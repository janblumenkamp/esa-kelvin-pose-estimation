{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Samples and Labels of the SPEED Dataset\n",
    "\n",
    "This notebook helps to inspect the SPEED dataset. You can see samples from the dataset, with the corresponding ground truth labels visualized as projected axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "#%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import mpl_toolkits.mplot3d as a3\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.collections import PolyCollection\n",
    "\n",
    "class Camera:\n",
    "\n",
    "    \"\"\"\" Utility class for accessing camera parameters. \"\"\"\n",
    "\n",
    "    fx = 0.0176  # focal length[m]\n",
    "    fy = 0.0176  # focal length[m]\n",
    "    nu = 1920  # number of horizontal[pixels]\n",
    "    nv = 1200  # number of vertical[pixels]\n",
    "    ppx = 5.86e-6  # horizontal pixel pitch[m / pixel]\n",
    "    ppy = ppx  # vertical pixel pitch[m / pixel]\n",
    "    fpx = fx / ppx  # horizontal focal length[pixels]\n",
    "    fpy = fy / ppy  # vertical focal length[pixels]\n",
    "    k = [[fpx,   0, nu / 2],\n",
    "         [0,   fpy, nv / 2],\n",
    "         [0,     0,      1]]\n",
    "    K = np.array(k)\n",
    "\n",
    "\n",
    "def process_json_dataset(root_dir):\n",
    "    with open(os.path.join(root_dir, 'train.json'), 'r') as f:\n",
    "        train_images_labels = json.load(f)\n",
    "\n",
    "    with open(os.path.join(root_dir, 'test.json'), 'r') as f:\n",
    "        test_image_list = json.load(f)\n",
    "\n",
    "    with open(os.path.join(root_dir, 'real_test.json'), 'r') as f:\n",
    "        real_test_image_list = json.load(f)\n",
    "\n",
    "    partitions = {'test': [], 'train': [], 'real_test': []}\n",
    "    labels = {}\n",
    "\n",
    "    for image_ann in train_images_labels:\n",
    "        partitions['train'].append(image_ann['filename'])\n",
    "        labels[image_ann['filename']] = {'q': image_ann['q_vbs2tango'], 'r': image_ann['r_Vo2To_vbs_true']}\n",
    "\n",
    "    for image in test_image_list:\n",
    "        partitions['test'].append(image['filename'])\n",
    "\n",
    "    for image in real_test_image_list:\n",
    "        partitions['real_test'].append(image['filename'])\n",
    "\n",
    "    return partitions, labels\n",
    "\n",
    "\n",
    "def quat2dcm(q):\n",
    "\n",
    "    \"\"\" Computing direction cosine matrix from quaternion, adapted from PyNav. \"\"\"\n",
    "\n",
    "    # normalizing quaternion\n",
    "    q = q/np.linalg.norm(q)\n",
    "\n",
    "    q0 = q[0]\n",
    "    q1 = q[1]\n",
    "    q2 = q[2]\n",
    "    q3 = q[3]\n",
    "\n",
    "    dcm = np.zeros((3, 3))\n",
    "\n",
    "    dcm[0, 0] = 2 * q0 ** 2 - 1 + 2 * q1 ** 2\n",
    "    dcm[1, 1] = 2 * q0 ** 2 - 1 + 2 * q2 ** 2\n",
    "    dcm[2, 2] = 2 * q0 ** 2 - 1 + 2 * q3 ** 2\n",
    "\n",
    "    dcm[0, 1] = 2 * q1 * q2 + 2 * q0 * q3\n",
    "    dcm[0, 2] = 2 * q1 * q3 - 2 * q0 * q2\n",
    "\n",
    "    dcm[1, 0] = 2 * q1 * q2 - 2 * q0 * q3\n",
    "    dcm[1, 2] = 2 * q2 * q3 + 2 * q0 * q1\n",
    "\n",
    "    dcm[2, 0] = 2 * q1 * q3 + 2 * q0 * q2\n",
    "    dcm[2, 1] = 2 * q2 * q3 - 2 * q0 * q1\n",
    "\n",
    "    return dcm\n",
    "\n",
    "def pointInTriangle(t, p):\n",
    "    #https://stackoverflow.com/questions/2049582/how-to-determine-if-a-point-is-in-a-2d-triangle\n",
    "    a = 0.5 *(-t[1][1]*t[2][0] + t[0][1]*(-t[1][0] + t[2][0]) + t[0][0]*(t[1][1] - t[2][1]) + t[1][0]*t[2][1]);\n",
    "    s = 1/(2*a)*(t[0][1]*t[2][0] - t[0][0]*t[2][1] + (t[2][1] - t[0][1])*p[0] + (t[0][0] - t[2][0])*p[1]);\n",
    "    u = 1/(2*a)*(t[0][0]*t[1][1] - t[0][1]*t[1][0] + (t[0][1] - t[1][1])*p[0] + (t[1][0] - t[0][0])*p[1]);\n",
    "    return s > 0 and u > 0 and (1-s-u) > 0\n",
    "    \n",
    "class Plane:\n",
    "    def __init__(self, points):\n",
    "        if len(points) != 3:\n",
    "            raise ValueError(\"Plane always consists of three points\")\n",
    "        \n",
    "        self.points = np.asarray(points)\n",
    "        n = np.cross(points[1] - points[0], points[2] - points[0])\n",
    "        self.normal = n / np.linalg.norm(n, 2)\n",
    "    \n",
    "    def intersect(self, v):\n",
    "        ndotu = self.normal.dot(v)\n",
    "        if abs(ndotu) < 1e-6:\n",
    "            raise ValueError(\"Line is parallel to plane\")\n",
    " \n",
    "        return -self.points[0] - (self.normal.dot(-self.points[0]) / ndotu) * v + self.points[0]\n",
    "    \n",
    "    def intersects(self, v):\n",
    "        # First calculate intersection point of vector and this plane:\n",
    "        try:\n",
    "            intersection = self.intersect(v)\n",
    "        except ValueError:\n",
    "            # The vector is parallel to the line, so always return false (could be completely on it or completely off)\n",
    "            return False\n",
    "        \n",
    "        # We have a rotated 3D plane (i.e. z coordinates are level) and want to remove the\n",
    "        # z coordinates while keeping relations (i.e. project 3D plane to xy-plane)\n",
    "        # https://stackoverflow.com/questions/1023948/rotate-normal-vector-onto-axis-plane\n",
    "        zAxisNew = self.normal\n",
    "        xAxisOld = np.array([1,0,0])\n",
    "        if np.array_equal(np.absolute(zAxisNew), xAxisOld):\n",
    "            # the old x axis cannot be the same as the normal (the new z axis) since then the\n",
    "            # coordinate system is perpendicular to the xy plane. Therefore change x and z then\n",
    "            xAxisOld = np.array([0,0,1])\n",
    "        yAxisOld = np.array([0,1,0])\n",
    "        yAxisNew = np.cross(xAxisOld, zAxisNew)\n",
    "        xAxisNew = np.cross(zAxisNew, yAxisNew)\n",
    "        yAxisNew /= np.linalg.norm(yAxisNew, 2)\n",
    "        xAxisNew /= np.linalg.norm(xAxisNew, 2)\n",
    "        projected2dtriangle = np.asarray([[p.dot(xAxisNew), p.dot(yAxisNew)] for p in self.points])\n",
    "        # Now we know the 2d projection of the points of the polygon. Also project the 3d intersection point to the same plane\n",
    "        projected2dpoint = np.asarray([intersection.dot(xAxisNew), intersection.dot(yAxisNew)])\n",
    "        return intersection, pointInTriangle(projected2dtriangle, projected2dpoint)\n",
    "\n",
    "def getSatelliteModel():\n",
    "    b = 0.6\n",
    "    a = 0.75\n",
    "    d = 0.8\n",
    "    c = 0.32\n",
    "\n",
    "    #     0         1      \n",
    "    #     +---a-----+\n",
    "    #  d-/|   u    /|-c\n",
    "    # 3 +---------+ | 2\n",
    "    #   |w| y  z  |x|     (y: front, z: back)\n",
    "    # 4 | +-------|-+ 5\n",
    "    #   |/ v (0,0)|/-b \n",
    "    # 7 +---------+ 6\n",
    "    # reference points in satellite frame for drawing axes\n",
    "    return np.array([\n",
    "        [-a / 2,  d / 2, c], # 0\n",
    "        [ a / 2,  d / 2, c], # 1\n",
    "        [ a / 2, -d / 2, c], # 2\n",
    "        [-a / 2, -d / 2, c], # 3\n",
    "        [-a / 2,  b / 2, 0], # 4\n",
    "        [ a / 2,  b / 2, 0], # 5\n",
    "        [ a / 2, -b / 2, 0], # 6\n",
    "        [-a / 2, -b / 2, 0]  # 7\n",
    "    ]), np.array([\n",
    "        [0, 1, 2], [0, 3, 2], # u\n",
    "        [4, 5, 6], [4, 7, 6], # v\n",
    "        [0, 3, 7], [0, 4, 7], # w\n",
    "        [1, 2, 6], [1, 5, 6], # x\n",
    "        [3, 2, 6], [3, 7, 6], # y\n",
    "        [0, 1, 5], [0, 4, 5], # z\n",
    "    ])\n",
    "\n",
    "def project(q, r, plot=False):\n",
    "    \"\"\" Projecting points to image frame to draw axes \"\"\"\n",
    "    model_coordinates, cube_polygon_indices = getSatelliteModel()\n",
    "    p_axes = np.ones((model_coordinates.shape[0], model_coordinates.shape[1] + 1))\n",
    "    p_axes[:,:-1] = model_coordinates\n",
    "    points_body = np.transpose(p_axes)\n",
    "\n",
    "    # transformation to camera frame\n",
    "    pose_mat = np.hstack((np.transpose(quat2dcm(q)), np.expand_dims(r, 1)))\n",
    "    p_cam = np.dot(pose_mat, points_body)\n",
    "\n",
    "    # Indices of points describing 3 point triangles of the cube\n",
    "    # No point should intersect any of these triangles to be visible in the camera\n",
    "\n",
    "    if plot:\n",
    "        fig = plt.figure()\n",
    "        ax = Axes3D(fig)\n",
    "\n",
    "    points_camera_t = p_cam.transpose()\n",
    "    points_camera_collision_indices = []\n",
    "    for polygon_indices in cube_polygon_indices:\n",
    "        points_polygon = points_camera_t[polygon_indices]\n",
    "        plane = Plane(points_polygon)\n",
    "\n",
    "        if plot:\n",
    "            tri = a3.art3d.Poly3DCollection([plane.points], alpha=0.2)\n",
    "            tri.set_color([1,0,0])\n",
    "            tri.set_edgecolor('k')\n",
    "            ax.add_collection3d(tri)\n",
    "\n",
    "        for i, p in enumerate(points_camera_t):\n",
    "            intersection, intersects = plane.intersects(p)\n",
    "            if(intersects):\n",
    "                # The vector between camera origin and cube vertice intersects any of the 12 cube polygons.\n",
    "                # There are two border cases to check:\n",
    "                # 1) Sometimes an actual vertice intersects a neighboring polygon\n",
    "                # 2) The vector between camera and point intersects a polygon that actually is behind the point\n",
    "                dist_intersection = np.linalg.norm(intersection, 2)\n",
    "                dist_point = np.linalg.norm(p, 2)\n",
    "                if abs(dist_intersection - dist_point) > 0.01 and dist_intersection < dist_point and not i in points_camera_collision_indices:\n",
    "                    points_camera_collision_indices.append(i)\n",
    "                    if plot:\n",
    "                        ax.scatter([intersection[0]], [intersection[1]], [intersection[2]])\n",
    "\n",
    "    visible_points = np.ones(len(p_axes), dtype=bool)\n",
    "    visible_points[points_camera_collision_indices] = False\n",
    "\n",
    "    if plot:\n",
    "        for p in points_camera_t[visible_points]:\n",
    "            ax.plot([0, p[0]], [0, p[1]], [0, p[2]])\n",
    "\n",
    "        #ax.set_xlim(-1, 1)\n",
    "        #ax.set_ylim(-1, 1)\n",
    "        #ax.set_zlim(5, 7)\n",
    "        ax.autoscale()\n",
    "        ax.set_xlabel('X axis')\n",
    "        ax.set_ylabel('Y axis')\n",
    "        ax.set_zlabel('Z axis')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    p_cam = points_camera_t.transpose()\n",
    "\n",
    "    # getting homogeneous coordinates\n",
    "    points_camera_frame = p_cam / p_cam[2]\n",
    "    # projection to image plane\n",
    "    points_image_plane = Camera.K.dot(points_camera_frame)\n",
    "\n",
    "    x, y = (points_image_plane[0], points_image_plane[1])\n",
    "    return x, y, visible_points\n",
    "\n",
    "def projectOrientationSystem(q, r):\n",
    "\n",
    "    \"\"\" Projecting points to image frame to draw axes \"\"\"\n",
    "\n",
    "    # reference points in satellite frame for drawing axes\n",
    "    p_axes = np.array([[0, 0, 0, 1],\n",
    "                       [1, 0, 0, 1],\n",
    "                       [0, 1, 0, 1],\n",
    "                       [0, 0, 1, 1]])\n",
    "    points_body = np.transpose(p_axes)\n",
    "\n",
    "    # transformation to camera frame\n",
    "    pose_mat = np.hstack((np.transpose(quat2dcm(q)), np.expand_dims(r, 1)))\n",
    "    p_cam = np.dot(pose_mat, points_body)\n",
    "\n",
    "    # getting homogeneous coordinates\n",
    "    points_camera_frame = p_cam / p_cam[2]\n",
    "\n",
    "    # projection to image plane\n",
    "    points_image_plane = Camera.K.dot(points_camera_frame)\n",
    "\n",
    "    x, y = (points_image_plane[0], points_image_plane[1])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "class SatellitePoseEstimationDataset:\n",
    "\n",
    "    \"\"\" Class for dataset inspection: easily accessing single images, and corresponding ground truth pose data. \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir='/datasets/speed_debug'):\n",
    "        self.partitions, self.labels = process_json_dataset(root_dir)\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def get_image(self, i=0, split='train'):\n",
    "\n",
    "        \"\"\" Loading image as PIL image. \"\"\"\n",
    "\n",
    "        img_name = self.partitions[split][i]\n",
    "        img_name = os.path.join(self.root_dir, 'images', split, img_name)\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        return image\n",
    "\n",
    "    def get_pose(self, i=0):\n",
    "\n",
    "        \"\"\" Getting pose label for image. \"\"\"\n",
    "\n",
    "        img_id = self.partitions['train'][i]\n",
    "        q, r = self.labels[img_id]['q'], self.labels[img_id]['r']\n",
    "        return q, r\n",
    "\n",
    "    def visualize(self, i, partition='train', ax=None):\n",
    "\n",
    "        \"\"\" Visualizing image, with ground truth pose with axes projected to training image. \"\"\"\n",
    "\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "        img = self.get_image(i)\n",
    "        ax.imshow(img)\n",
    "\n",
    "        # no pose label for test\n",
    "        if partition == 'train':\n",
    "            q, r = self.get_pose(i)\n",
    "            xa, ya = projectOrientationSystem(q, r)\n",
    "            ax.arrow(xa[0], ya[0], xa[1] - xa[0], ya[1] - ya[0], color='r')\n",
    "            ax.arrow(xa[0], ya[0], xa[2] - xa[0], ya[2] - ya[0], color='g')\n",
    "            ax.arrow(xa[0], ya[0], xa[3] - xa[0], ya[3] - ya[0], color='b')\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_dir = './speed'\n",
    "dataset = SatellitePoseEstimationDataset(root_dir=dataset_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 4\n",
    "cols = 2\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "def drawBlob(img, pos, size=3, color=[255, 0, 0]):\n",
    "    for y in range(pos[1] - size, pos[1] + size):\n",
    "        for x in range(pos[0] - size, pos[0] + size):\n",
    "            img[y][x] = color\n",
    "\n",
    "# 1) 8 Kantenpunkte bestimmen\n",
    "# 2) 8 entspr. Flächen bestimmenn\n",
    "# 3) 8 Vektor zwischen Kameraprojektion und 3D Punkt bestimmen\n",
    "# 4) Überprüfen, ob die 8 Vektoren irgendeine der 8 Flächen durchschneiden. Wenn ja: Punkt verwerfen!\n",
    "\n",
    "for i in range(0, 1):\n",
    "    img = np.array(dataset.get_image(i))\n",
    "    q, r = dataset.get_pose(i)\n",
    "    xa, ya, visible = project(q, r)\n",
    "    for x, y, v in zip(xa, ya, visible):\n",
    "        if v and x >= 0.0 and y >= 0.0 and x <= Camera.nu and y <= Camera.nv:\n",
    "            drawBlob(img, (int(x), int(y)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasDataGenerator(Sequence):\n",
    "\n",
    "    \"\"\" DataGenerator for Keras to be used with fit_generator (https://keras.io/models/sequential/#fit_generator)\"\"\"\n",
    "\n",
    "    def __init__(self, label_list, speed_root, label_size, batch_size=32, dim=(224, 224), shuffle=True):\n",
    "\n",
    "        # loading dataset\n",
    "        self.image_root = os.path.join(speed_root, 'images', 'train')\n",
    "\n",
    "        # Initialization\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = self.labels = {label['filename']: {'q': label['q_vbs2tango'], 'r': label['r_Vo2To_vbs_true']}\n",
    "                                     for label in label_list}\n",
    "        self.list_IDs = [label['filename'] for label in label_list]\n",
    "        self.shuffle = shuffle\n",
    "        self.label_size = label_size\n",
    "        self.indexes = None\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        \"\"\" Denotes the number of batches per epoch. \"\"\"\n",
    "\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \"\"\" Generate one batch of data \"\"\"\n",
    "\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        return self.__data_generation(list_IDs_temp)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        \"\"\" Updates indexes after each epoch \"\"\"\n",
    "\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def drawBlob(self, img, pos, sigma=3):\n",
    "        # https://github.com/NVlabs/Deep_Object_Pose/blob/master/src/training/train.py#L851\n",
    "        w = int(sigma*3)\n",
    "        if pos[0]-w>=0 and pos[0]+w<img.shape[0] and pos[1]-w>=0 and pos[1]+w<img.shape[1]:\n",
    "            for i in range(int(pos[0])-w, int(pos[0])+w):\n",
    "                for j in range(int(pos[1])-w, int(pos[1])+w):\n",
    "                    img[i,j] = np.exp(-(((i - pos[0])**2 + (j - pos[1])**2)/(2*(sigma**2))))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "\n",
    "        \"\"\" Generates data containing batch_size samples \"\"\"\n",
    "\n",
    "        # Initialization\n",
    "        imgs = np.empty((self.batch_size, *self.dim, 1))\n",
    "        masks = np.zeros((self.batch_size, *self.dim, 8), dtype=np.float)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            img_path = os.path.join(self.image_root, ID)\n",
    "            img = keras_image.load_img(img_path, target_size=self.dim, color_mode = \"grayscale\")\n",
    "            imgs[i] = keras_image.img_to_array(img)\n",
    "\n",
    "            q, r = self.labels[ID]['q'], self.labels[ID]['r']\n",
    "            xa, ya, visibles = project(q, r)\n",
    "            for j, (x, y, visible) in enumerate(zip(xa, ya, visibles)):\n",
    "                x /= Camera.nu\n",
    "                y /= Camera.nv\n",
    "                if visible and x >= 0.0 and y >= 0.0 and x <= 1.0 and y <= 1.0:\n",
    "                    x_s, y_s = int(x * self.dim[1]), int(y * self.dim[0])\n",
    "                    self.drawBlob(masks[i][...,j], (x_s, y_s), self.label_size)\n",
    "\n",
    "        return imgs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up parameters\n",
    "params = {'dim': (480, 640),\n",
    "          'batch_size': 8,\n",
    "          'label_size': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Loading and splitting dataset\n",
    "with open(os.path.join(dataset_root_dir, 'train' + '.json'), 'r') as f:\n",
    "    label_list = json.load(f)\n",
    "train_labels = label_list[:int(len(label_list)*.8)]\n",
    "validation_labels = label_list[int(len(label_list)*.8):]\n",
    "\n",
    "# Data generators for training and validation\n",
    "training_generator = KerasDataGenerator(train_labels, dataset_root_dir, **params)\n",
    "validation_generator = KerasDataGenerator(validation_labels, dataset_root_dir, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, masks in training_generator:\n",
    "    print(imgs.shape, masks.shape)\n",
    "    for img, mask in zip(imgs, masks):        \n",
    "        # plot with various axes scales\n",
    "        plt.figure(figsize=(20, 20))\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(img.astype(np.uint8)[...,0], cmap='gray')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(mask[...,0], cmap='gray')\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, Dense, BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
    "    \"\"\"\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    \n",
    "    The jaccard distance loss is usefull for unbalanced datasets. This has been\n",
    "    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n",
    "    gradient.\n",
    "    \n",
    "    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n",
    "    \n",
    "    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n",
    "    @author: wassname\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth\n",
    "\n",
    "def soft_dice_loss(y_true, y_pred, epsilon=1e-6): \n",
    "    ''' \n",
    "    Soft dice loss calculation for arbitrary batch size, number of classes, and number of spatial dimensions.\n",
    "    Assumes the `channels_last` format.\n",
    "  \n",
    "    # Arguments\n",
    "        y_true: b x X x Y( x Z...) x c One hot encoding of ground truth\n",
    "        y_pred: b x X x Y( x Z...) x c Network output, must sum to 1 over c channel (such as after softmax) \n",
    "        epsilon: Used for numerical stability to avoid divide by zero errors\n",
    "    \n",
    "    # References\n",
    "        V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation \n",
    "        https://arxiv.org/abs/1606.04797\n",
    "        More details on Dice loss formulation \n",
    "        https://mediatum.ub.tum.de/doc/1395260/1395260.pdf (page 72)\n",
    "        \n",
    "        Adapted from https://github.com/Lasagne/Recipes/issues/99#issuecomment-347775022\n",
    "    '''\n",
    "    \n",
    "    # skip the batch and class axis for calculating Dice score\n",
    "    axes = tuple(range(1, len(y_pred.shape)-1)) \n",
    "    numerator = 2. * K.sum(y_pred * y_true, axes)\n",
    "    denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)\n",
    "    \n",
    "    return 1 - K.mean(numerator / (denominator + epsilon)) # average over classes and batch\n",
    "\n",
    "def focal_loss(target, output, gamma=2):\n",
    "    # https://github.com/keras-team/keras/issues/6261#issuecomment-358826560\n",
    "    output /= K.sum(output, axis=-1, keepdims=True)\n",
    "    eps = K.epsilon()\n",
    "    output = K.clip(output, eps, 1. - eps)\n",
    "    return -K.sum(K.pow(1. - output, gamma) * target * K.log(output), axis=-1)\n",
    "\n",
    "def conv_norm(inp, filters, conv=Conv2D, kernel_size=3):\n",
    "    c = conv(filters=filters, kernel_size=kernel_size, padding='same')(inp)\n",
    "    c = BatchNormalization()(c)\n",
    "    return LeakyReLU(0.1)(c)\n",
    "\n",
    "def encode(inp, filters):\n",
    "    c = conv_norm(inp, filters)\n",
    "    c = conv_norm(c, filters)\n",
    "    c = conv_norm(c, filters)\n",
    "    p = MaxPooling2D(pool_size=2)(c)\n",
    "    return c, p\n",
    "\n",
    "def decode(inp, shortcut, filters):\n",
    "    up = concatenate([Conv2DTranspose(filters, 2, strides=2, padding='same')(inp), shortcut], axis=3)\n",
    "    c = BatchNormalization()(up)\n",
    "    c = conv_norm(c, filters)\n",
    "    return conv_norm(c, filters)\n",
    "\n",
    "filters_encode_decode = [16,32,32,64,128]\n",
    "filters_middle = [256, 256, 256]\n",
    "\n",
    "layers = [Input(params['dim'] + (1,))]\n",
    "for i, filters in enumerate(filters_encode_decode):\n",
    "    c, p = encode(layers[-1], filters)\n",
    "    layers.append(c)\n",
    "    layers.append(p)\n",
    "\n",
    "for i, filters in enumerate(filters_middle):\n",
    "    layers.append(conv_norm(layers[-1], filters))\n",
    "\n",
    "for i, filters in enumerate(reversed(filters_encode_decode)):\n",
    "    layers.append(decode(layers[-1], layers[((len(filters_encode_decode) - i) * 2) - 1], filters))\n",
    "\n",
    "layers.append(Conv2D(8, (1, 1), activation='sigmoid')(layers[-1]))\n",
    "\n",
    "model = Model(inputs=[layers[0]], outputs=[layers[-1]])\n",
    "model.compile(optimizer = RMSprop(lr=1e03), loss = focal_loss, metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = \"m1.h5\"\n",
    "checkpoint = ModelCheckpoint(current_model,save_best_only=True, verbose=1, monitor=\"val_loss\")\n",
    "reduce = ReduceLROnPlateau(factor=0.1, patience=5, monitor='val_loss')\n",
    "earlyStopping = EarlyStopping(patience=20, verbose=1,monitor=\"val_loss\")\n",
    "history = model.fit_generator(\n",
    "    generator=training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    use_multiprocessing=True, # Only works if training data is loaded into RAM from HDF\n",
    "    workers=8,\n",
    "    callbacks=[earlyStopping, checkpoint, reduce],\n",
    "    epochs=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgs, masks in training_generator:\n",
    "    for img, mask in zip(imgs, masks):\n",
    "        pred = model.predict(np.asarray([img]))\n",
    "        \n",
    "        # plot with various axes scales\n",
    "        plt.figure(figsize=(20, 20))\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(img.astype(np.uint8)[...,0], cmap='gray')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(pred[0][...,2])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "index = 0\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# Read Image\n",
    "img = np.array(dataset.get_image(index))\n",
    "q, r = dataset.get_pose(index)\n",
    "xa, ya, visible = project(q, r)\n",
    "size = img.shape\n",
    "\n",
    "model_points_all, _ = getSatelliteModel()\n",
    "image_points_all = np.stack((xa, ya), axis=1)\n",
    "\n",
    "model_points = model_points_all[visible]\n",
    "image_points = image_points_all[visible]\n",
    "print(visible)\n",
    "print(model_points)\n",
    "print(image_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    " \n",
    "(success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, Camera.K, None)\n",
    "\n",
    "print(q, r)\n",
    "rot = np.zeros((3, 3), dtype=np.float)\n",
    "#cv2.Rodrigues(rotation_vector, rot)\n",
    "print(R.from_rotvec(rotation_vector[...,0]).as_quat(), translation_vector[...,0])\n",
    "#print(R.from_dcm(rot).as_euler('zyx', degrees=True), R.from_dcm(rot).as_euler('zyx', degrees=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 4\n",
    "cols = 2\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        dataset.visualize(i * rows + j, ax=axes[i][j])\n",
    "        axes[i][j].axis('off')\n",
    "fig.tight_layout() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "# We use this to draw a line sticking out of the nose\n",
    " \n",
    " \n",
    "(nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(1.0, 1.0, 1.0)]), rotation_vector, translation_vector, Camera.K, None)\n",
    " \n",
    "for p in image_points:\n",
    "    cv2.circle(img, (int(p[0]), int(p[1])), 5, (0,0,255), -1)\n",
    " \n",
    " \n",
    "p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
    "p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    " \n",
    "cv2.line(img, p1, p2, (255,0,0), 2)\n",
    " \n",
    "# Display image\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
